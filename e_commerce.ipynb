{"cells":[{"source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1709996758496,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"},"id":"145bbc0f-4d15-4e7b-b796-5ec0d9ab7702","cell_type":"code","execution_count":36,"outputs":[]},{"source":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","metadata":{"executionCancelledAt":null,"executionTime":68,"lastExecutedAt":1709996758565,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","outputsMetadata":{"0":{"height":77,"type":"stream"},"2":{"height":117,"type":"stream"},"4":{"height":117,"type":"stream"},"6":{"height":117,"type":"stream"},"8":{"height":57,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"35ddad8f-fa43-4bb3-894b-afef8d0bfd59","cell_type":"code","execution_count":37,"outputs":[]},{"source":"# Get the number of classes\nclasses = train_data.classes\nnum_classes = len(train_data.classes)\n\n# Define some relevant variables\nnum_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]\n        ","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1709996758616,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Get the number of classes\nclasses = train_data.classes\nnum_classes = len(train_data.classes)\n\n# Define some relevant variables\nnum_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]\n        "},"id":"e5d01322-e517-44b8-a68f-1ff0e291418f","cell_type":"code","execution_count":38,"outputs":[]},{"source":"class MultiClassImageClassifier(nn.Module):\n  \n    # Define the init method\n    def __init__(self, num_classes):\n        super(MultiClassImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flatten = nn.Flatten()\n\n        # Create a fully connected layer\n        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n        \n    def forward(self, x):\n        # Pass inputs through each layer\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        return x","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1709996758668,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"class MultiClassImageClassifier(nn.Module):\n  \n    # Define the init method\n    def __init__(self, num_classes):\n        super(MultiClassImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flatten = nn.Flatten()\n\n        # Create a fully connected layer\n        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n        \n    def forward(self, x):\n        # Pass inputs through each layer\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        return x"},"cell_type":"code","id":"e320b92d-a8f8-4371-a210-d0b7bd73b799","outputs":[],"execution_count":39},{"source":"dataloader_train = DataLoader(\n    train_data,\n    batch_size=10,\n    shuffle=True,\n)","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1709996758724,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"dataloader_train = DataLoader(\n    train_data,\n    batch_size=10,\n    shuffle=True,\n)"},"cell_type":"code","id":"fdc4e4d5-2a6c-4212-810f-1cf2ed9470a9","outputs":[],"execution_count":40},{"source":"def train_model(optimizer, net, num_epochs):\n    num_processed = 0\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(num_epochs):\n        running_loss = 0\n        num_processed = 0\n        for features, labels in dataloader_train:\n            optimizer.zero_grad()\n            outputs = net(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            num_processed += len(labels)\n        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n    train_loss = running_loss / len(dataloader_train)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1709996758780,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def train_model(optimizer, net, num_epochs):\n    num_processed = 0\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(num_epochs):\n        running_loss = 0\n        num_processed = 0\n        for features, labels in dataloader_train:\n            optimizer.zero_grad()\n            outputs = net(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            num_processed += len(labels)\n        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n    train_loss = running_loss / len(dataloader_train)"},"cell_type":"code","id":"dacdd7dd-2b4f-468f-98d0-fbd8cf46f7dc","outputs":[],"execution_count":41},{"source":"net = MultiClassImageClassifier(num_classes)\noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\ntrain_model(\n    optimizer=optimizer,\n    net=net,\n    num_epochs=1,\n)\n\n# Test the model on the test set\n              \n# Define the test set DataLoader\ndataloader_test = DataLoader(\n    test_data,\n    batch_size=10,\n    shuffle=False,\n)","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null},"cell_type":"code","id":"07d4d93a-396b-40e8-84dc-c89be2976aee","outputs":[],"execution_count":29},{"source":"accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1709996743336,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)"},"cell_type":"code","id":"d48e6604-dea5-4511-8e3d-3debf7ade3fc","outputs":[],"execution_count":30},{"source":"net.eval()\npredicted = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n    cat = torch.argmax(output, dim=-1)\n    predicted.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)\n","metadata":{"executionCancelledAt":null,"executionTime":9657,"lastExecutedAt":1709996752993,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"net.eval()\npredicted = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n    cat = torch.argmax(output, dim=-1)\n    predicted.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)\n"},"cell_type":"code","id":"a56f7b46-c8a1-4bac-a309-4fa8f37cd714","outputs":[],"execution_count":31},{"source":"accuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy:', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per class):', recall)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1709996753045,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"accuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy:', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per class):', recall)"},"cell_type":"code","id":"2a6435b0-9783-4b5d-b335-1efb9532926f","outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: 0.8830999732017517\nPrecision (per class): [0.8197845220565796, 0.9968487620353699, 0.7964683771133423, 0.8134135603904724, 0.839479386806488, 0.9843423962593079, 0.7368420958518982, 0.9211026430130005, 0.9736841917037964, 0.9557344317436218]\nRecall (per class): [0.8370000123977661, 0.9490000009536743, 0.8569999933242798, 0.9459999799728394, 0.7739999890327454, 0.9430000185966492, 0.6439999938011169, 0.968999981880188, 0.9620000123977661, 0.949999988079071]\n"}],"execution_count":32}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}